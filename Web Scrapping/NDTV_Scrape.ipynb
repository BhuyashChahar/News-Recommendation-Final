{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bhuyash./Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404\n",
      "404\n",
      "404\n",
      "404\n",
      "404\n",
      "404\n",
      "404\n",
      "Link: https://www.ndtv.com/business/earnings/page-8\n",
      "<class 'requests.exceptions.ConnectionError'> Line: 24\n",
      "404\n",
      "Link: https://www.ndtv.com/business/latest/page-7\n",
      "<class 'requests.exceptions.ConnectionError'> Line: 24\n",
      "404\n",
      "404\n",
      "404\n",
      "404\n",
      "404\n",
      "404\n",
      "404\n",
      "404\n",
      "404\n",
      "404\n",
      "404\n",
      "404\n",
      "404\n",
      "404\n",
      "404\n",
      "404\n",
      "404\n",
      "404\n",
      "404\n",
      "404\n",
      "404\n",
      "404\n",
      "404\n",
      "404\n",
      "404\n",
      "404\n",
      "404\n"
     ]
    }
   ],
   "source": [
    "import urllib.request, sys, time\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "news_count_threshold = 1000\n",
    "page_count = 1\n",
    "news_count = 1\n",
    "news_info = list()\n",
    "\n",
    "news_count = 1\n",
    "\n",
    "categories = {'business':['your-money', 'corporates','industries', 'economy', 'earnings', 'latest'],\n",
    "              'entertainment':['bollywood','hollywood','television']}\n",
    "\n",
    "for category in categories:\n",
    "        for subcategory in categories[category]:\n",
    "            for page_ in range(1,10):\n",
    "                if news_count <= news_count_threshold: \n",
    "                    news_url = \"https://www.ndtv.com/{}/{}/page-{}\".format(category, subcategory, page_) \n",
    "                \n",
    "                    try:\n",
    "                        page = requests.get(news_url)\n",
    "                    \n",
    "                        \n",
    "                        if page.status_code != 200: \n",
    "                            print(page.status_code)\n",
    "                            continue   \n",
    "\n",
    "                        soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "                        news_heading_tags = soup.find_all(\"h2\", class_ = \"newsHdng\")\n",
    "\n",
    "                        news_links_list = list()\n",
    "                        for news_heading_tag in news_heading_tags:\n",
    "                            news_links_list.append(news_heading_tag.find_all(\"a\")[0].get(\"href\"))\n",
    "\n",
    "                        for link in news_links_list:\n",
    "                            # Delaying the Get Request by 2 Seconds \n",
    "                            time.sleep(2)\n",
    "\n",
    "                            try:\n",
    "                                page_in = requests.get(link)\n",
    "                                \n",
    "                                if page_in.status_code != 200:\n",
    "                                    print(page.status_code)\n",
    "                                    continue\n",
    "\n",
    "                                soup_in = BeautifulSoup(page_in.content, \"html.parser\")\n",
    "\n",
    "                                \n",
    "                                # Fetching Date and Time \n",
    "                                news_datetime_in = soup_in.find_all(\"span\", itemprop = \"dateModified\")[0].get_text().strip()\n",
    "#                                print(news_datetime_in)\n",
    "                                news_datetime_in_list = news_datetime_in.split()[1:]\n",
    "                                news_date_in = \" \".join(news_datetime_in_list[:3])\n",
    "                                news_time_in = \" \".join(news_datetime_in_list[3:])\n",
    "                                temp_news_info = [news_date_in, news_time_in, category, subcategory]\n",
    "\n",
    "                                # Fetching News Heading \n",
    "                                news_heading_in = soup_in.find_all(\"h1\", itemprop = \"headline\")\n",
    "#                                print(news_heading_in)\n",
    "#                                print(len(news_heading_in))\n",
    "#                                print(\"-\"*120)\n",
    "                                news_heading_in = news_heading_in[0].get_text().strip()\n",
    "                                temp_news_info.append(news_heading_in)\n",
    "                                \n",
    "                                # Fetching News Summary \n",
    "                                news_summary_in = soup_in.find_all(\"h2\", class_ = \"sp-descp\")\n",
    "                                news_summary_in = news_summary_in[0].get_text().strip()\n",
    "                                temp_news_info.append(news_summary_in)                                \n",
    "\n",
    "\n",
    "                                # Fetching News Content \n",
    "                                news_content_in = soup_in.find_all('p', class_ = None)\n",
    "#                                print(news_content_in)\n",
    "#                                print(len(news_content_in))\n",
    "                                news_content_in = \" \".join([news_content_in_para.get_text().strip() for news_content_in_para in news_content_in])\n",
    "                                news_content_in = re.sub(\"Follow Us: \\.+ Advertisement \\.+\", \"\", news_content_in)\n",
    "#                                print(news_content_in)\n",
    "#                                print(\"*\"*120)\n",
    "                                temp_news_info.append(news_content_in)\n",
    "                                \n",
    "                                # Fetching News Author \n",
    "                                news_author_in = soup_in.find_all(\"span\", itemprop = \"author\")\n",
    "                                news_author_in = news_author_in[0].get_text().strip()\n",
    "                                temp_news_info.append(news_author_in)                                \n",
    "\n",
    "\n",
    "                                 # Adding URL to the temp_news_info List \n",
    "                                temp_news_info.append(link)\n",
    "\n",
    "                                # Appending the temp_news_info List Into news_info List \n",
    "                                news_info.append(temp_news_info)\n",
    "\n",
    "                                # Increasing the News Count by 1 Since the News Web Page has Successfully been Scraped \n",
    "                                if news_count == news_count_threshold: # round(news_count_threshold - (news_count_threshold/2)):\n",
    "                                    news_count += 1\n",
    "                                    break\n",
    "                                elif news_count < news_count_threshold: # round(news_count_threshold - (news_count_threshold/2)):\n",
    "                                    news_count += 1\n",
    "                            \n",
    "                            except Exception as e:\n",
    "                                error_type, error_obj, error_info = sys.exc_info()\n",
    "                                print(\"Link:\", link)\n",
    "                                print(error_type, \"Line:\", error_info.tb_lineno)\n",
    "                                continue\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        error_type, error_obj, error_info = sys.exc_info()\n",
    "                        print(\"Link:\", news_url)\n",
    "                        print(error_type, \"Line:\", error_info.tb_lineno)\n",
    "                        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_dataframe = pd.DataFrame(news_info, columns = [\"Date\", \"Time\", \"Category\", \"Subcategory\", \"Heading\", \"Summary\",\n",
    "                                                    \"Entire_News\", \"Author\", \n",
    "                                                    \"News_Link\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Category</th>\n",
       "      <th>Subcategory</th>\n",
       "      <th>Heading</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Entire_News</th>\n",
       "      <th>Author</th>\n",
       "      <th>News_Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Date, Time, Category, Subcategory, Heading, Summary, Entire_News, Author, News_Link]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No engine for filetype: 'csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOptionError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/excel/_base.py:1136\u001b[0m, in \u001b[0;36mExcelWriter.__new__\u001b[0;34m(cls, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs)\u001b[0m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1136\u001b[0m     engine \u001b[38;5;241m=\u001b[39m \u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_option\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mio.excel.\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mext\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.writer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1137\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/_config/config.py:274\u001b[0m, in \u001b[0;36mCallableDynamicDoc.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[0;32m--> 274\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__func__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/_config/config.py:146\u001b[0m, in \u001b[0;36m_get_option\u001b[0;34m(pat, silent)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_option\u001b[39m(pat: \u001b[38;5;28mstr\u001b[39m, silent: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 146\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[43m_get_single_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;66;03m# walk the nested dict\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/_config/config.py:132\u001b[0m, in \u001b[0;36m_get_single_key\u001b[0;34m(pat, silent)\u001b[0m\n\u001b[1;32m    131\u001b[0m         _warn_if_deprecated(pat)\n\u001b[0;32m--> 132\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OptionError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such keys(s): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(pat)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(keys) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[0;31mOptionError\u001b[0m: \"No such keys(s): 'io.excel.csv.writer'\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnews_dataframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNDTV_scraped_news.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#Writing to Excel file\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/util/_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    332\u001b[0m     )\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/generic.py:2417\u001b[0m, in \u001b[0;36mNDFrame.to_excel\u001b[0;34m(self, excel_writer, sheet_name, na_rep, float_format, columns, header, index, index_label, startrow, startcol, engine, merge_cells, inf_rep, freeze_panes, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m   2404\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mformats\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexcel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExcelFormatter\n\u001b[1;32m   2406\u001b[0m formatter \u001b[38;5;241m=\u001b[39m ExcelFormatter(\n\u001b[1;32m   2407\u001b[0m     df,\n\u001b[1;32m   2408\u001b[0m     na_rep\u001b[38;5;241m=\u001b[39mna_rep,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2415\u001b[0m     inf_rep\u001b[38;5;241m=\u001b[39minf_rep,\n\u001b[1;32m   2416\u001b[0m )\n\u001b[0;32m-> 2417\u001b[0m \u001b[43mformatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2418\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexcel_writer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2419\u001b[0m \u001b[43m    \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msheet_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2420\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstartrow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstartrow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2421\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstartcol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstartcol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2422\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfreeze_panes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreeze_panes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2423\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2424\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2425\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2426\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/formats/excel.py:943\u001b[0m, in \u001b[0;36mExcelFormatter.write\u001b[0;34m(self, writer, sheet_name, startrow, startcol, freeze_panes, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m    941\u001b[0m     need_save \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    942\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 943\u001b[0m     writer \u001b[38;5;241m=\u001b[39m \u001b[43mExcelWriter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    949\u001b[0m     need_save \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/excel/_base.py:1140\u001b[0m, in \u001b[0;36mExcelWriter.__new__\u001b[0;34m(cls, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs)\u001b[0m\n\u001b[1;32m   1138\u001b[0m             engine \u001b[38;5;241m=\u001b[39m get_default_engine(ext, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwriter\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1139\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 1140\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo engine for filetype: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   1142\u001b[0m \u001b[38;5;66;03m# for mypy\u001b[39;00m\n\u001b[1;32m   1143\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m engine \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: No engine for filetype: 'csv'"
     ]
    }
   ],
   "source": [
    "news_dataframe.to_excel('NDTV_scraped_news.csv', index=False)#Writing to Excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
